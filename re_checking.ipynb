{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from Bio import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq as SeqO\n",
    "\n",
    "\n",
    "import cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load restrictions sites and codon tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_restriction_sites():\n",
    "\n",
    "    re_seqs = []\n",
    "    for record in SeqIO.parse(cfg.RESTRICTSITES_FN, 'fasta'):\n",
    "        re_seqs.append(record.seq)\n",
    "        re_seqs.append(record.seq.reverse_complement())\n",
    "\n",
    "    return(set(re_seqs))\n",
    "\n",
    "def load_hs_codon_freq():\n",
    "    '''\n",
    "    Generate aa to codon dictionary.\n",
    "    '''\n",
    "\n",
    "    aa_codon_dt = pd.read_csv(cfg.DATA_DIR+'hs_codon_freq.csv')\n",
    "    aa_to_codon = dict(aa_codon_dt.loc[\n",
    "            aa_codon_dt.groupby('aa')['freq'].idxmax()][\n",
    "                    ['aa','codon']].to_dict('split')['data'])\n",
    "\n",
    "    return(aa_codon_dt, aa_to_codon)\n",
    "\n",
    "AA_CODON_DT, AA_TO_CODON = load_hs_codon_freq()\n",
    "\n",
    "def rand_codon(aa, orig=None):\n",
    "    '''\n",
    "    select random codon\n",
    "    based on hs genome freq\n",
    "    '''\n",
    "    codon_rows = AA_CODON_DT[AA_CODON_DT['aa'] == aa]\n",
    "    if orig:\n",
    "\n",
    "        for codon in orig:\n",
    "            codon_rows = codon_rows[codon_rows.codon != codon]\n",
    "\n",
    "        if not len(codon_rows):\n",
    "            #no other codons, can't use orig\n",
    "            return None\n",
    "    return(np.random.choice(\n",
    "            codon_rows.codon,\n",
    "            p = codon_rows.freq/sum(codon_rows.freq)))\n",
    "\n",
    "RE_SITES = load_restriction_sites()\n",
    "RE_REGEX = regex.compile('('+'|'.join([str(re).replace('N','.') for re in RE_SITES])+')')\n",
    "LIBRARY = pd.read_csv('out/results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RE Check\n",
    "\n",
    "Load the dictionary of mutated sequences generated by the TCR_library program from a saved CSV file. I then iterate through\n",
    "the dataframe and extract the mutant DNA and AA sequence. These sequences are then fed to the remove_re_sites function.\n",
    "remove_re_sites searches for instances of the specified site (including overlapping sequences) using the finditer function\n",
    "provided in the regex module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def identify_unique_codons(library):\n",
    "    \"\"\"\n",
    "\n",
    "    :param library:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    used_codons = []\n",
    "\n",
    "    current_aa_i = None\n",
    "    codons_at_aa_i = None\n",
    "\n",
    "    for sequence in library.iterrows(): #Iterate through CSV and convert back into sequence dictionary\n",
    "        position = sequence[1][1]\n",
    "\n",
    "        original_aa = sequence[1][2]\n",
    "        original_codon = sequence[1][3]\n",
    "        new_aa = sequence[1][4]\n",
    "        new_codon = str(sequence[1][5])\n",
    "\n",
    "        if position != current_aa_i:\n",
    "            current_aa_i = position\n",
    "            codons_at_aa_i = [original_codon]\n",
    "            used_codons += [codons_at_aa_i]\n",
    "\n",
    "        if new_codon != 'nan': codons_at_aa_i += [new_codon]\n",
    "\n",
    "    return used_codons\n",
    "\n",
    "def remove_re_sites(\n",
    "        nt_seq, aa_seq, used_codons,\n",
    "        pre=cfg.OLIGO_CHECK_PRE,\n",
    "        post=cfg.OLIGO_CHECK_POST,\n",
    "        re_regex= RE_REGEX,\n",
    "        v= False):\n",
    "\n",
    "    #Reformat input sequences to uppercase\n",
    "    nt_seq = nt_seq.upper()\n",
    "    pre = pre.upper()\n",
    "    post = post.upper()\n",
    "\n",
    "    assert(Seq.Seq(nt_seq).translate() == aa_seq)\n",
    "\n",
    "    re_matches = re_regex.finditer(pre+nt_seq+post, overlapped = 1)\n",
    "    replacements = 0\n",
    "    codon_indices_replaced = []\n",
    "    aa_replaced = []\n",
    "    old_codons = []\n",
    "    new_codons = []\n",
    "\n",
    "    while re_matches:\n",
    "\n",
    "        try:\n",
    "            match = next(re_matches)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "\n",
    "        if v:\n",
    "            print('replacements:{}'.format(replacements))\n",
    "            print(pre.lower() + nt_seq + post.lower())\n",
    "            print('global match:'+str(match))\n",
    "\n",
    "        if replacements > 100:\n",
    "            if v: print('too many codon replacement attempts') # something is up\n",
    "            return None,None,used_codons\n",
    "        # get span of nucleotide indices\n",
    "\n",
    "        nt_span = (\n",
    "                max([0, match.span()[0]- len(pre)]),\n",
    "                min([len(nt_seq), match.span()[1] - len(pre)]))\n",
    "\n",
    "        # expand to corresponding codon indices\n",
    "        aa_span = [i // 3 for i in nt_span]\n",
    "\n",
    "        # convert codon indices back to nucleotides\n",
    "        nt_rep_span = (aa_span[0]*3, aa_span[1]*3+3)\n",
    "\n",
    "        if v: print('spans:'+str(nt_span)+str(aa_span)+str(nt_rep_span))\n",
    "\n",
    "        # try replacing one codon at a time:\n",
    "        for codon_i in random.sample(\n",
    "                range(aa_span[0], aa_span[1]),\n",
    "                aa_span[1]-aa_span[0]):\n",
    "\n",
    "            old_codon = [nt_seq[(codon_i*3):((codon_i*3)+3)]]\n",
    "            if v: print(codon_i)\n",
    "\n",
    "            new_codon = rand_codon(aa_seq[codon_i], orig=used_codons[codon_i])\n",
    "\n",
    "            if new_codon is None:\n",
    "                continue\n",
    "\n",
    "            if v: print(new_codon)\n",
    "\n",
    "            used_codons[codon_i] += [new_codon]\n",
    "\n",
    "            if v:\n",
    "                print('changing codon {}:{}({}) to {}({})'.format(\n",
    "                        codon_i,\n",
    "                        old_codon,\n",
    "                        aa_seq[codon_i],\n",
    "                        new_codon,\n",
    "                        Seq.Seq(new_codon).translate()))\n",
    "\n",
    "            new_nt_seq = (\n",
    "                    nt_seq[:(codon_i*3)] +\n",
    "                    new_codon +\n",
    "                    nt_seq[((codon_i*3)+3):])\n",
    "\n",
    "            # print('new seq: '+pre+new_nt_seq+post)\n",
    "            # test for same match as found originally\n",
    "            local_re_match = re_regex.search((pre+new_nt_seq+post)[\n",
    "                    match.span()[0]:match.span()[1]])\n",
    "            if v: print('local match: '+str(local_re_match))\n",
    "\n",
    "            # if no more match, we're done, accept new seq\n",
    "            if not local_re_match:\n",
    "                nt_seq = new_nt_seq\n",
    "                codon_indices_replaced.append(codon_i)\n",
    "                aa_replaced.append(aa_seq[codon_i])\n",
    "                old_codons.append(old_codon)\n",
    "                new_codons.append(new_codon)\n",
    "                break\n",
    "\n",
    "        replacements += 1\n",
    "        #redo search to see if we still have restriction sites\n",
    "\n",
    "        re_matches = re_regex.finditer(pre+nt_seq+post, overlapped = 1)\n",
    "\n",
    "    assert(Seq.Seq(nt_seq).translate() == aa_seq), '{} ne {}'.format(\n",
    "        Seq.Seq(nt_seq).translate(),\n",
    "        aa_seq)\n",
    "\n",
    "    return(nt_seq, zip(\n",
    "            codon_indices_replaced,\n",
    "            aa_replaced,\n",
    "            old_codons,\n",
    "            new_codons), used_codons)\n",
    "\n",
    "def screen_library_for_re_sites(library, used_codons):\n",
    "    \"\"\"\n",
    "\n",
    "    :param library:\n",
    "    :param used_codons:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    screened_sequences = []\n",
    "    re_sites_removed = 0\n",
    "    no_alternative_codon = 0\n",
    "\n",
    "    print(\"Size of initial library: \" + str(len(library)))\n",
    "    print(\"Removing restriction sites... \\n\")\n",
    "\n",
    "    for sequence in library.iterrows(): #Iterate through CSV and convert back into sequence dictionary\n",
    "\n",
    "        screened_sequence = {\n",
    "            'position': sequence[1][1],\n",
    "            'original_aa': sequence[1][2],\n",
    "            'original_codon': sequence[1][3],\n",
    "            'new_aa': sequence[1][4],\n",
    "            'new_codon': sequence[1][5],\n",
    "            'new_dna_seq': sequence[1][6],\n",
    "            'new_aa_seq': sequence[1][7],\n",
    "            \"dna_change_s\": sequence[1][8],\n",
    "            \"dna_change_e\": sequence[1][9]\n",
    "        }\n",
    "\n",
    "        aa_i = screened_sequence['position']\n",
    "        new_aa = screened_sequence['new_aa']\n",
    "\n",
    "        dna_sequence_pre = screened_sequence['new_dna_seq']\n",
    "        aa_sequence_pre = screened_sequence['new_aa_seq']\n",
    "\n",
    "        dna_sequence_post, re_info, used_codons = remove_re_sites(dna_sequence_pre,aa_sequence_pre, used_codons) #Check for RE sites\n",
    "\n",
    "        if dna_sequence_post is None:\n",
    "            no_alternative_codon += 1\n",
    "            continue\n",
    "\n",
    "        re_info = list(re_info)\n",
    "\n",
    "        if len(re_info) > 0: #Update the DNA sequence if a site if found\n",
    "            re_sites_removed += 1\n",
    "            dna_i = aa_i * 3\n",
    "            original_codon = screened_sequence['new_codon']\n",
    "\n",
    "            if new_aa != \"DEL\" and original_codon != dna_sequence_post[dna_i: dna_i + 3]:\n",
    "                new_codon = dna_sequence_post[dna_i: dna_i + 3]\n",
    "                screened_sequence[\"new_codon\"] = new_codon\n",
    "\n",
    "                changed_dna_i = [dna_i + i for i in range(len(original_codon)) if original_codon[i] != new_codon[i]]\n",
    "                screened_sequence['dna_change_s'] = int(min(changed_dna_i))\n",
    "                screened_sequence['dna_change_e'] = int(max(changed_dna_i))\n",
    "\n",
    "            screened_sequence['new_dna_seq'] = dna_sequence_post\n",
    "\n",
    "        screened_sequences += [screened_sequence]\n",
    "\n",
    "    print(\"Removal complete!\")\n",
    "    print(\"Sequences with restriction sites removed: \" + str(re_sites_removed))\n",
    "    print(\"Sequences with no alternative/unique codon: \" + str(no_alternative_codon))\n",
    "    print(\"Screened library size: \" + str(len(screened_sequences)))\n",
    "    return pd.DataFrame(screened_sequences), re_sites_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of initial library: 1903\n",
      "Removing restriction sites... \n",
      "\n",
      "Removal complete!\n",
      "Sequences with restriction sites removed: 23\n",
      "Sequences with no alternative/unique codon: 3\n",
      "Screened library size: 1900\n",
      "Running QC on library \n",
      "\n"
     ]
    }
   ],
   "source": [
    "USED_CODONS = identify_unique_codons(LIBRARY)\n",
    "\n",
    "screened_library, re_sites = screen_library_for_re_sites(LIBRARY, USED_CODONS)\n",
    "def library_qc(library):\n",
    "\n",
    "    print('Running QC on library \\n')\n",
    "\n",
    "    for sequence in library.iterrows(): #Iterate through CSV and convert back into sequence dictionary\n",
    "\n",
    "        screened_sequence = {\n",
    "            'position': sequence[1][0],\n",
    "            'original_aa': sequence[1][1],\n",
    "            'original_codon': sequence[1][2],\n",
    "            'new_aa': sequence[1][3],\n",
    "            'new_codon': sequence[1][4],\n",
    "            'new_dna_seq': sequence[1][5],\n",
    "            'new_aa_seq': sequence[1][6],\n",
    "            \"dna_change_s\": sequence[1][7],\n",
    "            \"dna_change_e\": sequence[1][8]\n",
    "        }\n",
    "\n",
    "        if screened_sequence['new_aa'] not in  ['DEL','STOP']:\n",
    "            assert SeqO(screened_sequence['new_codon']).translate() == screened_sequence['new_aa']\n",
    "            assert screened_sequence['new_aa_seq'][screened_sequence['position']] == screened_sequence['new_aa']\n",
    "\n",
    "        assert SeqO(screened_sequence['new_dna_seq']).translate( ) == screened_sequence['new_aa_seq']\n",
    "\n",
    "library_qc(screened_library)\n",
    "screened_library.to_csv('out/screened_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}